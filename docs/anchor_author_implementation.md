# é”šç‚¹ä½œè€…ç³»ç»Ÿ â€” å®æ–½è®¾è®¡

> ä»ç†è®ºæ¨¡å‹åˆ°å¯è¿è¡Œä»£ç çš„è½åœ°æ–¹æ¡ˆã€‚
> ç†è®ºåŸºç¡€è§ `anchor_source_authority_model.md`ã€‚

---

## 0. æ ¸å¿ƒé—®é¢˜

arXiv æ¯å¤© ~500 ç¯‡ CS è®ºæ–‡ï¼Œç”¨æˆ·ä¸å¯èƒ½å…¨è¯»ã€‚é”šç‚¹ä½œè€…ç³»ç»Ÿçš„ç›®æ ‡ï¼š

1. **è‡ªåŠ¨å‘ç°**ç”¨æˆ·åº”è¯¥å…³æ³¨çš„é«˜è´¨é‡ä½œè€…ï¼ˆä¸ä¾èµ–æ‰‹åŠ¨è®¢é˜…ï¼‰
2. **æœç´¢å¢å¼º**ï¼šæ¯æ¬¡æœç´¢åæ ‡æ³¨å“ªäº›ç»“æœå‘½ä¸­äº†é”šç‚¹ä½œè€…
3. **é˜²è¿‡æ‹Ÿåˆ**ï¼šä¸ç›²ä¿¡ç”¨æˆ·å“å‘³ï¼Œç”¨å®¢è§‚è´¨é‡æ ¡å‡†ä¸»è§‚åå¥½
4. **åˆä½œç½‘ç»œ**ï¼šæ­ç¤ºä½œè€…é—´çš„åˆä½œå…³ç³»å’Œæœºæ„èšç±»

---

## 1. æ•°æ®å±‚ï¼šauthors + paper_authors

### 1.1 ä¸ºä»€ä¹ˆä¸ç»§ç»­ç”¨ authors_json

å½“å‰ `PaperModel.authors_json` å­˜çš„æ˜¯ `["John Smith", "Jane Doe"]`ï¼Œå­˜åœ¨ï¼š
- åŒä¸€äººå¤šç§å†™æ³•ï¼ˆ"Yann LeCun" / "Y. LeCun"ï¼‰
- æ— æ³•è·¨è®ºæ–‡èšåˆç»Ÿè®¡
- æ— æ³•å…³è” Semantic Scholar author ID

### 1.2 æ–°è¡¨è®¾è®¡

```sql
-- ä½œè€…å®ä½“è¡¨
CREATE TABLE authors (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name_normalized TEXT NOT NULL,        -- å°å†™å»ç©ºæ ¼ï¼Œç”¨äºå»é‡
    display_name TEXT NOT NULL,           -- å±•ç¤ºç”¨åŸå
    semantic_scholar_id TEXT,             -- S2 author IDï¼ˆå»¶è¿Ÿè§£æï¼‰
    affiliation TEXT,                     -- æœºæ„ï¼ˆå»¶è¿Ÿè§£æï¼‰
    h_index INTEGER,
    citation_count INTEGER DEFAULT 0,
    paper_count INTEGER DEFAULT 0,
    resolved_at DATETIME,                 -- S2 API è§£ææ—¶é—´
    created_at DATETIME NOT NULL,
    UNIQUE(name_normalized)
);
CREATE INDEX idx_authors_s2id ON authors(semantic_scholar_id);
CREATE INDEX idx_authors_name ON authors(name_normalized);

-- è®ºæ–‡-ä½œè€…å¤šå¯¹å¤šå…³è”
CREATE TABLE paper_authors (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    paper_id INTEGER NOT NULL REFERENCES papers(id) ON DELETE CASCADE,
    author_id INTEGER NOT NULL REFERENCES authors(id) ON DELETE CASCADE,
    position INTEGER NOT NULL DEFAULT 0,  -- 0-basedï¼Œ0=ä¸€ä½œ
    UNIQUE(paper_id, author_id)
);
CREATE INDEX idx_paper_authors_author ON paper_authors(author_id);
CREATE INDEX idx_paper_authors_paper ON paper_authors(paper_id);
```

### 1.3 Name Normalization

```python
def normalize_author_name(name: str) -> str:
    """è½»é‡çº§å§“åå½’ä¸€åŒ–ï¼Œä¸ä¾èµ–å¤–éƒ¨æœåŠ¡ã€‚"""
    name = name.strip().lower()
    name = re.sub(r'\s+', ' ', name)
    # å»æ‰ä¸­é—´åç¼©å†™: "yann a. lecun" â†’ "yann lecun"
    name = re.sub(r'\b[a-z]\.\s*', '', name)
    # å»æ‰å°¾éƒ¨é€—å·æ ¼å¼: "lecun, yann" â†’ "yann lecun"
    if ',' in name:
        parts = [p.strip() for p in name.split(',', 1)]
        name = f"{parts[1]} {parts[0]}"
    return name.strip()
```

ç²¾ç¡®å»é‡é  `name_normalized` UNIQUE çº¦æŸã€‚åç»­å¯¹ top ä½œè€…è°ƒ S2 Author Search API è¡¥å…¨ `semantic_scholar_id`ï¼Œå®ç°è·¨å†™æ³•åˆå¹¶ã€‚

### 1.4 å›å¡«ç­–ç•¥

è¿ç§»åä¸€æ¬¡æ€§æ‰«æ `papers.authors_json`ï¼š

```python
for paper in all_papers:
    for i, name in enumerate(paper.get_authors()):
        norm = normalize_author_name(name)
        author = get_or_create_author(norm, display_name=name)
        link_paper_author(paper.id, author.id, position=i)
```

åç»­æ¯æ¬¡ `paper_store.upsert_paper()` æ—¶åŒæ­¥å†™å…¥ `paper_authors`ã€‚

---

## 2. åŒè½¨è¯„åˆ†ï¼šé˜²è¿‡æ‹Ÿåˆ

### 2.1 é—®é¢˜

çº¯é ç”¨æˆ· save è¡Œä¸ºæ¨è = ä¿¡æ¯èŒ§æˆ¿ã€‚åˆå­¦è€…å¯èƒ½ save è´¨é‡ä¸€èˆ¬çš„è®ºæ–‡ã€‚

### 2.2 è§£æ³•ï¼šSubjective + Objective è‡ªé€‚åº”æ··åˆ

```
anchor_score = Î± Ã— subjective_score + (1 - Î±) Ã— objective_score
```

Î± éšç”¨æˆ·æˆç†Ÿåº¦åŠ¨æ€è°ƒæ•´ï¼š

```python
import math

def compute_alpha(user_total_saves: int, calibration: float) -> float:
    """
    Î± âˆˆ [0.1, 0.7]ï¼Œæ°¸è¿œä¸ä¼šå®Œå…¨å¿½ç•¥å®¢è§‚åˆ†ã€‚
    calibration: ç”¨æˆ· save ä¸ judge score çš„ç›¸å…³æ€§ (0~1)
    """
    raw = 1 / (1 + math.exp(-(user_total_saves - 20) / 8))
    return 0.1 + 0.6 * raw * calibration
```

- æ–°ç”¨æˆ· (saves < 10): Î± â‰ˆ 0.1 â†’ å®¢è§‚è´¨é‡ä¸»å¯¼
- æˆç†Ÿç”¨æˆ· (saves > 30) + é«˜æ ¡å‡†: Î± â‰ˆ 0.5 â†’ ä¸»è§‚å®¢è§‚å„åŠ
- Î± ä¸Šé™ 0.7 â†’ å®¢è§‚åˆ†æ°¸è¿œè‡³å°‘å  30%

### 2.3 Objective Scoreï¼ˆä¸ä¾èµ–ç”¨æˆ·è¡Œä¸ºï¼‰

é’ˆå¯¹æ¯ä¸ª authorï¼Œä»ç³»ç»Ÿå…¨å±€æ•°æ®è®¡ç®—ï¼š

| ä¿¡å· | æƒé‡ | æ¥æº |
|------|------|------|
| `judge_score_avg` | 0.35 | è¯¥ä½œè€…æ‰€æœ‰è®ºæ–‡çš„ `paper_judge_scores.overall` å¹³å‡å€¼ |
| `citation_velocity` | 0.25 | `papers.citation_count / age_years`ï¼ˆlog scaleï¼‰ |
| `venue_tier_avg` | 0.20 | è®ºæ–‡å‘è¡¨ venue çš„å¹³å‡ tierï¼ˆT1=1.0, T2=0.6, other=0.2ï¼‰ |
| `h_index_norm` | 0.20 | `log(1 + h_index) / log(1 + field_median_h)`ï¼ˆé¢†åŸŸå½’ä¸€åŒ–ï¼‰ |

```python
def objective_score(author_id: int) -> float:
    papers = get_author_papers(author_id)
    if not papers:
        return 0.0

    judge_avg = mean([p.judge_overall for p in papers if p.judge_overall]) or 0
    cite_vel = mean([p.citation_count / max(age_years(p), 0.5) for p in papers])
    venue_avg = mean([venue_tier_score(p.venue) for p in papers])
    h_norm = math.log(1 + (author.h_index or 0)) / math.log(1 + 30)  # 30 as field median

    return (0.35 * min(judge_avg / 5.0, 1.0) +
            0.25 * min(math.log(1 + cite_vel) / 5.0, 1.0) +
            0.20 * venue_avg +
            0.20 * min(h_norm, 1.0))
```

### 2.4 Subjective Scoreï¼ˆæ¥è‡ªç”¨æˆ·è¡Œä¸ºï¼‰

é’ˆå¯¹ç‰¹å®š userï¼Œä» `paper_feedback(action=save)` èšåˆï¼š

| ä¿¡å· | æƒé‡ | è¯´æ˜ |
|------|------|------|
| `save_count` | 0.40 | å‡ºç°åœ¨å¤šå°‘ç¯‡ saved paper ä¸Š |
| `recency` | 0.25 | æœ€è¿‘ save çš„æ—¶é—´è¡°å‡ï¼ˆåŠè¡°æœŸ 90 å¤©ï¼‰ |
| `track_spread` | 0.20 | è·¨å¤šå°‘ä¸ª research track |
| `first_author_ratio` | 0.15 | ä¸€ä½œæ¯”ä¾‹ |

### 2.5 ç”¨æˆ·æ ¡å‡†ï¼ˆCalibrationï¼‰

è¿½è¸ªç”¨æˆ· save çš„è®ºæ–‡çš„ judge score åˆ†å¸ƒï¼š

```python
def compute_calibration(user_id: str) -> float:
    """ç”¨æˆ·å“å‘³ä¸å®¢è§‚è´¨é‡çš„ä¸€è‡´æ€§ï¼Œ0~1ã€‚"""
    saved_papers = get_user_saved_papers(user_id)
    if len(saved_papers) < 5:
        return 0.3  # æ•°æ®ä¸è¶³ï¼Œä¿å®ˆå€¼

    judge_scores = [p.judge_overall for p in saved_papers if p.judge_overall]
    if not judge_scores:
        return 0.3

    avg = mean(judge_scores)
    # judge overall æ»¡åˆ† 5.0ï¼Œavg >= 3.5 è¯´æ˜ç”¨æˆ·å“å‘³é è°±
    return min(max((avg - 2.0) / 2.0, 0.0), 1.0)
```

### 2.6 é”šç‚¹åˆ†å±‚

| å±‚çº§ | anchor_score | æ ‡ç­¾ | ç³»ç»Ÿè¡Œä¸º |
|------|-------------|------|---------|
| Core Anchor | >= 0.7 | `anchor` | æ–°è®ºæ–‡è‡ªåŠ¨é«˜ä¼˜å…ˆçº§ï¼Œæœç´¢ç»“æœç½®é¡¶ |
| Rising | 0.4 ~ 0.7 | `rising` | å€¼å¾—å…³æ³¨ï¼Œæœç´¢ç»“æœæ ‡æ³¨ |
| Background | < 0.4 | â€” | ä¸å±•ç¤º |

---

## 3. Search Hit Overlay â€” æœç´¢ç»“æœé”šç‚¹å‘½ä¸­

### 3.1 æ•°æ®æµ

```
ç”¨æˆ·æœç´¢ â†’ Context Engine è¿”å› papers
    â†’ æå–æ‰€æœ‰ paper çš„ author_ids (via paper_authors)
    â†’ æŸ¥è¯¢ user çš„ anchor authors
    â†’ äº¤å‰åŒ¹é… â†’ ç”Ÿæˆ anchor_hits overlay
    â†’ è¿”å›ç»™å‰ç«¯
```

### 3.2 åç«¯å“åº”æ‰©å±•

åœ¨ç°æœ‰æœç´¢å“åº”ä¸­æ–°å¢ `anchor_hits` å­—æ®µï¼š

```json
{
  "papers": [...],
  "anchor_hits": {
    "summary": {
      "total_results": 20,
      "anchor_hit_count": 4,
      "hit_rate": 0.20
    },
    "by_author": [
      {
        "author_name": "Yann LeCun",
        "author_id": 42,
        "tier": "anchor",
        "anchor_score": 0.92,
        "hit_paper_ids": [101, 205],
        "track_stats": {
          "track_name": "self-supervised-learning",
          "saved_in_track": 5,
          "this_is_nth": [6, 7]
        }
      }
    ]
  }
}
```

### 3.3 å‰ç«¯å±•ç¤º

- PaperCard ä½œè€…åæ—ï¼š`âš“ Anchor Â· è¯¥ track ç¬¬ 6 ç¯‡`
- æœç´¢ç»“æœé¡¶éƒ¨ç»Ÿè®¡æ ï¼š`4/20 results from your anchor authors (20%)`
- Rising ä½œè€…ç”¨ä¸åŒé¢œè‰² badge

### 3.4 Track è®¡æ•°é€»è¾‘

"è¿™æ˜¯è¯¥ä½œè€…åœ¨è¿™ä¸ª track çš„ç¬¬ N ç¯‡" çš„è®¡ç®—ï¼š

```sql
SELECT COUNT(*) + 1 as nth
FROM paper_feedback pf
JOIN paper_authors pa ON pa.paper_id = pf.paper_ref_id
WHERE pf.user_id = :user_id
  AND pf.track_id = :track_id
  AND pf.action = 'save'
  AND pa.author_id = :author_id
```

---

## 4. åˆä½œç½‘ç»œ + æœºæ„å…³ç³»

### 4.1 Co-author å…±ç°å›¾

ä» `paper_authors` æ„å»ºï¼šåŒä¸€ç¯‡è®ºæ–‡çš„ä¸¤ä¸ªä½œè€…ä¹‹é—´å»ºç«‹ edgeã€‚

```python
def build_coauthor_edges(user_id: str) -> list[dict]:
    """ä»ç”¨æˆ· saved papers æ„å»ºå…±ç°è¾¹ã€‚"""
    saved_paper_ids = get_saved_paper_ids(user_id)
    edges = defaultdict(int)

    for paper_id in saved_paper_ids:
        authors = get_paper_author_ids(paper_id)
        for a, b in combinations(authors, 2):
            key = (min(a, b), max(a, b))
            edges[key] += 1

    return [
        {"source": a, "target": b, "weight": w}
        for (a, b), w in edges.items()
        if w >= 2  # è‡³å°‘åˆä½œ 2 ç¯‡æ‰å»ºè¾¹
    ]
```

### 4.2 æœºæ„èšç±»

æŒ‰ `authors.affiliation` åˆ†ç»„ï¼ˆéœ€ S2 API è§£æåæ‰æœ‰æ•°æ®ï¼‰ï¼š

```json
{
  "clusters": [
    {
      "institution": "UC Berkeley",
      "author_count": 5,
      "total_saved_papers": 12,
      "top_authors": ["Dawn Song", "Pieter Abbeel"]
    },
    {
      "institution": "Google DeepMind",
      "author_count": 8,
      "total_saved_papers": 15,
      "top_authors": ["Demis Hassabis", "Oriol Vinyals"]
    }
  ]
}
```

### 4.3 åç«¯ç«¯ç‚¹

```
GET /research/scholars/network?user_id=default&min_edge_weight=2
```

è¿”å› `{ nodes: [...], edges: [...], clusters: [...] }`

---

## 5. æ¢ç´¢æœºåˆ¶ â€” æ‰“ç ´ä¿¡æ¯èŒ§æˆ¿

### 5.1 Community Picks

ä¸ä¾èµ–ä»»ä½•ç”¨æˆ·è¡Œä¸ºï¼Œçº¯å®¢è§‚è´¨é‡æ¨èï¼š

```python
def community_picks(track_id: int, limit: int = 10) -> list:
    """åœ¨ track é¢†åŸŸå†…ï¼Œjudge åˆ†æ•° top çš„ä½œè€…ï¼ˆæ’é™¤ç”¨æˆ·å·²æœ‰é”šç‚¹ï¼‰ã€‚"""
    track = get_track(track_id)
    keywords = track.get_keywords()

    # æ‰¾åˆ°è¯¥é¢†åŸŸè®ºæ–‡
    papers = search_papers(keywords=keywords, min_judge_score=3.5)

    # æŒ‰ä½œè€…èšåˆ judge åˆ†æ•°
    author_scores = defaultdict(list)
    for p in papers:
        for author_id in get_paper_author_ids(p.id):
            author_scores[author_id].append(p.judge_overall)

    # æ’åºï¼šå¹³å‡ judge score Ã— è®ºæ–‡æ•°æƒé‡
    ranked = sorted(
        author_scores.items(),
        key=lambda x: mean(x[1]) * math.log(1 + len(x[1])),
        reverse=True
    )
    return ranked[:limit]
```

### 5.2 Blind Spot Detection

æ£€æµ‹ç”¨æˆ·å“ªäº› track ç¼ºå°‘é”šç‚¹è¦†ç›–ï¼š

```python
def detect_blind_spots(user_id: str) -> list[dict]:
    tracks = get_user_tracks(user_id)
    anchors = get_user_anchors(user_id)

    blind_spots = []
    for track in tracks:
        track_anchor_count = count_anchors_in_track(anchors, track.id)
        if track_anchor_count == 0:
            community = community_picks(track.id, limit=5)
            blind_spots.append({
                "track": track.name,
                "message": f"No anchors in '{track.name}' yet",
                "suggested_authors": community
            })
    return blind_spots
```

### 5.3 Serendipity Injection

æœç´¢ç»“æœä¸­æ··å…¥ 10-15% çš„éé”šç‚¹ä½†å®¢è§‚è´¨é‡é«˜çš„è®ºæ–‡ï¼Œè®©ç”¨æˆ·æœ‰æœºä¼šå‘ç°æ–°ä½œè€…ã€‚åœ¨ Context Engine çš„ç»“æœæ’åºä¸­å®ç°ã€‚

---

## 6. API ç«¯ç‚¹è®¾è®¡

| æ–¹æ³• | è·¯å¾„ | è¯´æ˜ |
|------|------|------|
| `GET` | `/research/scholars/discover` | é”šç‚¹å‘ç°ï¼šè¿”å›åŒè½¨è¯„åˆ†æ’åºçš„ä½œè€…åˆ—è¡¨ |
| `GET` | `/research/scholars/community` | Community Picksï¼šçº¯å®¢è§‚è´¨é‡æ¨è |
| `GET` | `/research/scholars/network` | åˆä½œç½‘ç»œå›¾ï¼šnodes + edges + clusters |
| `GET` | `/research/scholars/blind-spots` | ç›²åŒºæ£€æµ‹ï¼šç¼ºå°‘é”šç‚¹çš„ track |
| `POST` | `/research/scholars/{author_id}/resolve` | è§¦å‘ S2 API è§£æè¡¥å…¨ |

### 6.1 Discover ç«¯ç‚¹è¯¦ç»†

```
GET /research/scholars/discover?user_id=default&limit=30&include_community=true
```

å“åº”ï¼š

```json
{
  "anchors": [
    {
      "author_id": 42,
      "name": "Yann LeCun",
      "tier": "anchor",
      "anchor_score": 0.92,
      "objective_score": 0.88,
      "subjective_score": 0.95,
      "save_count": 8,
      "avg_judge_score": 4.2,
      "avg_citations": 1250,
      "tracks": ["deep-learning", "self-supervised"],
      "recent_papers": ["A Path Towards Autonomous AI"],
      "affiliation": "Meta AI / NYU",
      "h_index": 180,
      "semantic_scholar_id": "1688681"
    }
  ],
  "community_picks": [...],
  "blind_spots": [...],
  "user_calibration": 0.72,
  "alpha": 0.45
}
```

---

## 7. å‰ç«¯ Scholars é¡µé¢æ”¹é€ 

### 7.1 é¡µé¢ç»“æ„

```
/scholars
â”œâ”€â”€ Tab: Discovered (é»˜è®¤)
â”‚   â”œâ”€â”€ ç»Ÿè®¡æ : "12 anchors Â· 8 rising Â· calibration: 72%"
â”‚   â”œâ”€â”€ Your Anchors (åŒè½¨è¯„åˆ† top N)
â”‚   â”‚   â””â”€â”€ AuthorCard: name, tier badge, score, save_count, tracks, affiliation
â”‚   â”œâ”€â”€ Community Picks (çº¯å®¢è§‚æ¨è)
â”‚   â”‚   â””â”€â”€ AuthorCard + "Community Recommended" badge
â”‚   â””â”€â”€ Blind Spots (ç¼ºå°‘é”šç‚¹çš„ track)
â”‚       â””â”€â”€ "No anchors in 'CV' track â€” suggested: ..."
â”œâ”€â”€ Tab: Network
â”‚   â””â”€â”€ åŠ›å¯¼å‘å›¾ / ç®€å•åˆ—è¡¨å±•ç¤ºåˆä½œç½‘ç»œ
â””â”€â”€ Tab: Subscribed
    â””â”€â”€ ç°æœ‰æ‰‹åŠ¨è®¢é˜…å­¦è€…ï¼ˆä¿ç•™ï¼‰
```

### 7.2 AuthorCard ç»„ä»¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Avatar]  Yann LeCun          âš“ Anchor (0.92)  â”‚
â”‚           Meta AI / NYU Â· h-index: 180          â”‚
â”‚                                                  â”‚
â”‚  ğŸ“Š Obj: 0.88  ğŸ‘¤ Subj: 0.95  ğŸ“„ 8 saved       â”‚
â”‚  Tracks: deep-learning, self-supervised          â”‚
â”‚                                                  â”‚
â”‚  Recent: "A Path Towards Autonomous AI" (2025)   â”‚
â”‚                                                  â”‚
â”‚  [Resolve Profile]  [View Details]  [Follow]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. Search Hit Overlay å‰ç«¯

### 8.1 æœç´¢ç»“æœé¡¶éƒ¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¯ Anchor Coverage: 4/20 results (20%)          â”‚
â”‚    LeCun: 2 hits Â· He: 1 hit Â· Bengio: 1 hit   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 PaperCard å†…åµŒæ ‡æ³¨

åœ¨ç°æœ‰ PaperCard çš„ä½œè€…è¡Œä¸­ï¼Œé”šç‚¹ä½œè€…åå­—åè¿½åŠ ï¼š

```
Authors: Yann LeCun âš“, Kaiming He ğŸ“ˆ, ...
         â””â”€ Anchor Â· self-supervised track ç¬¬ 6 ç¯‡
```

---

## 9. å®æ–½é¡ºåº

è¯¦è§ `ANCHOR_TODO.md`ã€‚

P0ï¼ˆæœ€å°é—­ç¯ï¼‰: å»ºè¡¨ â†’ å›å¡« â†’ discover ç«¯ç‚¹ â†’ å‰ç«¯æ›¿æ¢ mock
P1ï¼ˆæœç´¢å¢å¼ºï¼‰: search hit overlay â†’ PaperCard æ ‡æ³¨
P2ï¼ˆç½‘ç»œ + è§£æï¼‰: åˆä½œç½‘ç»œ â†’ S2 API è§£æ â†’ æœºæ„èšç±»
P3ï¼ˆæ™ºèƒ½æ¨èï¼‰: anchor boost in Context Engine â†’ blind spot â†’ serendipity
